{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal: Train the 2nd order polynomial predictor using both gradient descent and stochastic gradient descent. Optimize the stepsizes and compare against scikit-learn implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download data from https://drive.google.com/file/d/0Bz9_0VdXvv9bUUNlUTVrMF9VcVU/view?usp=sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from copy import deepcopy\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/jurajkapasny/Drive/Data/NBA/'\n",
    "nb = pd.read_csv(data_path+'nba_games_2013_2015.csv', delimiter=';')\n",
    "x = nb[['AST','REB','STL']]\n",
    "y = nb['PTS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a function psi(x), which transforms features AST (assists), REB (rebounds) and STL (steals) into 2nd order polynomial features (add each feature squared and each pair of features multiplied with every other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(x):\n",
    "    res = deepcopy(x)\n",
    "    res[\"1\"] = 1\n",
    "    res[\"AST2\"] = x.AST * x.AST\n",
    "    res[\"REB2\"] = x.REB * x.REB\n",
    "    res[\"STL2\"] = x.STL * x.STL\n",
    "    res[\"ASTSTL\"] = x.AST * x.STL\n",
    "    res[\"REBSTL\"] = x.REB * x.STL\n",
    "    res[\"ASTREB\"] = x.AST * x.REB\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a transformed data matrix X, where each x is mapped to psi(x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = psi(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AST</th>\n",
       "      <th>REB</th>\n",
       "      <th>STL</th>\n",
       "      <th>1</th>\n",
       "      <th>AST2</th>\n",
       "      <th>REB2</th>\n",
       "      <th>STL2</th>\n",
       "      <th>ASTSTL</th>\n",
       "      <th>REBSTL</th>\n",
       "      <th>ASTREB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1681</td>\n",
       "      <td>1849</td>\n",
       "      <td>196</td>\n",
       "      <td>574</td>\n",
       "      <td>602</td>\n",
       "      <td>1763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>529</td>\n",
       "      <td>1849</td>\n",
       "      <td>64</td>\n",
       "      <td>184</td>\n",
       "      <td>344</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>1521</td>\n",
       "      <td>49</td>\n",
       "      <td>140</td>\n",
       "      <td>273</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>361</td>\n",
       "      <td>2209</td>\n",
       "      <td>36</td>\n",
       "      <td>114</td>\n",
       "      <td>282</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>441</td>\n",
       "      <td>1849</td>\n",
       "      <td>16</td>\n",
       "      <td>84</td>\n",
       "      <td>172</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AST  REB  STL  1  AST2  REB2  STL2  ASTSTL  REBSTL  ASTREB\n",
       "0   41   43   14  1  1681  1849   196     574     602    1763\n",
       "1   23   43    8  1   529  1849    64     184     344     989\n",
       "2   20   39    7  1   400  1521    49     140     273     780\n",
       "3   19   47    6  1   361  2209    36     114     282     893\n",
       "4   21   43    4  1   441  1849    16      84     172     903"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a function p2(x,w), which outputs the value of the polynomial at x for given parameters w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p2(x,w):\n",
    "    df = deepcopy(x)\n",
    "    df = psi(df)\n",
    "    w = np.array(w)\n",
    "    return (df * w).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       130.37\n",
       "1        76.19\n",
       "2        61.21\n",
       "3        74.51\n",
       "4        64.97\n",
       "         ...  \n",
       "7375     63.01\n",
       "7376     79.59\n",
       "7377     97.25\n",
       "7378     78.85\n",
       "7379     61.53\n",
       "Length: 7380, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2(x, [0.06, 0.05,0.03,0.01,0.02,0.02,0.04, 0.03,0.02,0.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create a function Loss(X,y,w), which computes the squared loss of predicting y from X by p2(x,w) using parameters w. Take variable PTS as y. We will predict scored points based on assists, rebounds and steals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(x,y,w):\n",
    "    y_pred = p2(x, w)\n",
    "    err = y - y_pred\n",
    "    return np.mean(err**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891.9364108807604"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = [0.06, 0.05,0.03,0.01,0.02,0.02,0.04, 0.03,0.02,0.01]\n",
    "loss(x,y,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Code up the gradient descent. It should input a point w and a stepsize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_descent(X, y, alpha, w, max_iters):\n",
    "    # using deep copy, \n",
    "    # Assignment statements in Python do not copy objects, they create bindings between a target and an object.\n",
    "    # when you want to have actual copy, it's better to use deepcopy\n",
    "    df = deepcopy(X)\n",
    "    #transforming df to 2nd degree polynom\n",
    "    df = psi(df)\n",
    "    \n",
    "    #number of observation in X and y\n",
    "    m = len(y)\n",
    "    \n",
    "    loss_func_history = []\n",
    "#     w_history = []\n",
    "#     w = np.array(w)\n",
    "#     w_history.append(w)\n",
    "    # computing initial loss\n",
    "    loss_func_history.append(loss(X,y,w))\n",
    "    \n",
    "    # for each iteration\n",
    "    for k in range(max_iters):\n",
    "        # compute predictions with actual w\n",
    "        predictions = p2(X, w)\n",
    "        # number of coefients\n",
    "        w_size = len(w)\n",
    "        \n",
    "        # computing gradient of each w separately (approximates partial derivation of function)\n",
    "        for i in range(w_size):\n",
    "            #taking 1 variable only from the dataframe\n",
    "            temp = df.iloc[:, i]\n",
    "            #errors multiply by the variable in place\n",
    "            errors_x1 = (predictions - y) * temp\n",
    "            # adjusting w[i]\n",
    "            # gradient is basically sum of the erros divided by number of observation, np.mean could be used as well\n",
    "            w[i] = w[i] - alpha * (1.0 / m) * errors_x1.sum()\n",
    "\n",
    "        loss_func_history.append(loss(X,y,w))\n",
    "#         w_history.append(w)\n",
    "    return loss_func_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Choose an arbitrary point and stepsize. Run gradient descent for 100 iterations and compute the Loss after each iteration. How does the loss behave? Does it converge to something?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func_history = grad_descent(x,y,alpha=0.00001, w=np.ones(10), max_iters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func_history[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Can you find the stepsize, for which the loss is smallest after 100 iterations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jurajkapasny/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0.1\n",
      "Step: 0.01\n",
      "Step: 0.001\n",
      "Step: 0.0001\n",
      "Step: 1e-05\n",
      "Step: 1e-06\n",
      "Step: 1e-07\n",
      "Step: 1e-08\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "steps = [1, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001, 0.00000001]\n",
    "for alpha in steps:\n",
    "    print(f\"Step: {alpha}\")\n",
    "    losses.append(grad_descent(x,y,alpha=alpha, w=np.ones(10), max_iters=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
